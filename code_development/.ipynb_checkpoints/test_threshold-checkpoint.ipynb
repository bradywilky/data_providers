{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75aebfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# helper function to create a dataframe with each source and the number of times the source has been used by ACLED\n",
    "def _get_tot_cnt_df(df):\n",
    "    sql = lambda q: sqldf(q, locals())\n",
    "    \n",
    "    tot_cnt_df = sqldf(f'''\n",
    "        SELECT source_singular,\n",
    "        count(*) total\n",
    "        FROM df\n",
    "        GROUP BY source_singular\n",
    "    ''', locals())\n",
    "    \n",
    "    return tot_cnt_df\n",
    "    \n",
    "# helper function to modify column names to work with pandasql\n",
    "def _clean(c):\n",
    "    for r in [' ', '-', '/']:\n",
    "        c = c.replace(r, '_')\n",
    "    \n",
    "    for r in ['.', ',']:\n",
    "        c = c.replace(r, '')\n",
    "    \n",
    "    return c\n",
    "\n",
    "\n",
    "# filter dataframe to get tags for each source that meet the criteria to be a tag\n",
    "# params:\n",
    "#  tag_col: name of column to use as tag\n",
    "#  dst_df: df of distinct tagging values (required for SQL)\n",
    "#  type_pct_df: df of the percents of each tag in each source (required for SQL)\n",
    "#  total_min: the minimum number of times the source has been used by ACLED\n",
    "#  total_max: the maximum number of times the source has been used by ACLED\n",
    "#  pct_min: the minimum percent of events per source required to be from the tag value\n",
    "\n",
    "def _generate_tag_df(tag_col, dst_df, type_pct_df, total_min, total_max, pct_min):\n",
    "    # required for pandasql to work properly\n",
    "    type_pct_df_sql = type_pct_df\n",
    "    \n",
    "    # creating empty dataframe for each source, potential tag value, total times used with the potential tag value,\n",
    "    # and percentage of times used with the potential tag value\n",
    "    df = pd.DataFrame(columns=[\n",
    "        'source_singular',\n",
    "        tag_col,\n",
    "        f'{tag_col}_total',\n",
    "        f'{tag_col}_pct'\n",
    "    ])\n",
    "    \n",
    "    # iterating through every potential tag value and appending candidate tagged sources to the empty dataframe\n",
    "    for t in dst_df[tag_col]:\n",
    "        t_cln = _clean(t)\n",
    "        t_cln_pct_nm = t_cln + '_pct'\n",
    "\n",
    "        query = f'''\n",
    "        SELECT\n",
    "            source_singular,\n",
    "            \"{t_cln}_majority\" AS \"{tag_col}\",\n",
    "            {t_cln} AS \"{tag_col}_total\",\n",
    "            {t_cln_pct_nm} AS {tag_col}_pct\n",
    "        FROM\n",
    "            type_pct_df\n",
    "        WHERE \n",
    "            total >= {total_min}\n",
    "            AND total <= {total_max}\n",
    "            AND {t_cln_pct_nm} >= {pct_min}\n",
    "        '''\n",
    "\n",
    "        df1 = sqldf(query, locals())\n",
    "        df = pd.concat([df, df1])\n",
    "        \n",
    "    # returning dataframe of sources and candidate tags \n",
    "    return df\n",
    "\n",
    "\n",
    "# takes extended DF as parameter\n",
    "def tag_sub_event_type(df, total_min, total_max, pct_min):\n",
    "\n",
    "    # getting distinct list of specific event types from the \"sub_event_type\" column\n",
    "    typ_df = sqldf('''\n",
    "        SELECT DISTINCT sub_event_type\n",
    "        FROM df\n",
    "    ''', locals())\n",
    "\n",
    "    # generating query to get binary indicators for each sub_event_type\n",
    "    query_fmt = ''\n",
    "    for i, t in enumerate(typ_df['sub_event_type']):\n",
    "        t_cln = t.replace(\" \", \"_\")\n",
    "        t_cln = t_cln.replace(\"/\", \"_\")\n",
    "        query_fmt += f'sum(CASE WHEN sub_event_type = \"{t}\" THEN 1 ELSE 0 END ) AS \"{t_cln}\"'\n",
    "        if i < len(src_df['sub_event_type']) - 1:\n",
    "            query_fmt += ',\\n'\n",
    "\n",
    "    # applying above query\n",
    "    type_cnt_df = sqldf(f'''\n",
    "        SELECT source_singular,\n",
    "        {query_fmt}\n",
    "        FROM df\n",
    "        GROUP BY source_singular\n",
    "    ''', locals())\n",
    "\n",
    "    # getting dataframe of each source and the total of how many times the source was used by ACLED in an event\n",
    "    tot_cnt_df = _get_tot_cnt_df(df)\n",
    "    \n",
    "    # generating query to get percent of sub_event_type reported on by each source for each sub_event_type\n",
    "    query_fmt = ''\n",
    "    for i, t in enumerate(typ_df['sub_event_type']):\n",
    "        t_cln = t.replace(\" \", \"_\")\n",
    "        t_cln = t_cln.replace(\"/\", \"_\")\n",
    "        t_cln_pct_nm = t_cln + '_pct'\n",
    "        query_fmt += f'cast({t_cln} AS DOUBLE) / cast(total AS DOUBLE) \"{t_cln_pct_nm}\"'\n",
    "        if i < len(src_df['sub_event_type']) - 1:\n",
    "            query_fmt += ',\\n'\n",
    "\n",
    "    # applying above query\n",
    "    type_pct_df = sqldf(f'''\n",
    "        SELECT\n",
    "            a.*,\n",
    "            b.total,\n",
    "            {query_fmt}\n",
    "        FROM type_cnt_df a\n",
    "        JOIN tot_cnt_df b\n",
    "            ON a.source_singular = b.source_singular\n",
    "    ''', locals())\n",
    "\n",
    "    # filter dataframe to get sub_event_type for each source that meet the criteria to be a tag\n",
    "    sub_event_type_df = _generate_tag_df('sub_event_type', typ_df, type_pct_df, total_min, total_max, pct_min)\n",
    "    \n",
    "    return sub_event_type_df\n",
    "\n",
    "\n",
    "\n",
    "# takes extended DF as parameter\n",
    "def tag_country(df, total_min, total_max, pct_min):\n",
    "\n",
    "    # getting distinct list of geographical locations (countries) from the \"country\" column\n",
    "    geo_df = sqldf('''\n",
    "        SELECT DISTINCT country\n",
    "        FROM df\n",
    "    ''', locals())\n",
    "\n",
    "    # generating query to get binary indicators for each country\n",
    "    query_fmt = ''\n",
    "    for i, t in enumerate(geo_df['country']):\n",
    "        t_cln = _clean(t)\n",
    "        query_fmt += f'sum(CASE WHEN country = \"{t}\" THEN 1 ELSE 0 END ) AS \"{t_cln}\"'\n",
    "        if i < len(geo_df['country']) - 1:\n",
    "            query_fmt += ',\\n'\n",
    "\n",
    "    # applying above query\n",
    "    type_cnt_df = sqldf(f'''\n",
    "    SELECT source_singular,\n",
    "    {query_fmt}\n",
    "    FROM df\n",
    "    GROUP BY source_singular\n",
    "    ''', locals())\n",
    "    \n",
    "    # getting dataframe of each source and the total of how many times the source was used by ACLED in an event\n",
    "    tot_cnt_df = _get_tot_cnt_df(df)\n",
    "    \n",
    "    # generating query to get percent of countries reported on by each source for each country\n",
    "    query_fmt = ''\n",
    "    for i, t in enumerate(geo_df['country']):\n",
    "        t_cln = _clean(t)\n",
    "        t_pct_nm = t_cln + '_pct'\n",
    "        query_fmt += f'cast({t_cln} AS DOUBLE) / cast(total AS DOUBLE) \"{t_pct_nm}\"'\n",
    "        if i < len(geo_df['country']) - 1:\n",
    "            query_fmt += ',\\n'\n",
    "    \n",
    "    # applying above query\n",
    "    type_pct_df = sqldf(f'''\n",
    "    SELECT\n",
    "        a.*,\n",
    "        b.total,\n",
    "    {query_fmt}\n",
    "    FROM type_cnt_df a\n",
    "    JOIN tot_cnt_df b\n",
    "        ON a.source_singular = b.source_singular\n",
    "    ''', locals())\n",
    "    \n",
    "    # filter dataframe to get countries for each source that meet the criteria to be a tag\n",
    "    cntry_df = _generate_tag_df('country', geo_df, type_pct_df, total_min, total_max, pct_min)\n",
    "    \n",
    "    return cntry_df\n",
    "\n",
    "\n",
    "# takes extended DF as parameter\n",
    "def tag_time_period(df, n_clusters=4, init='random', n_init=10, max_iter=100, tol=1e-04, random_state=0):\n",
    "    # setting up K-Means clustering model to identify time periods to tag the data with\n",
    "    km = KMeans(\n",
    "        n_clusters=n_clusters, init=init,\n",
    "        n_init=n_init, max_iter=max_iter, \n",
    "        tol=tol, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # creating df that will be clustered by \"event_date\"\n",
    "    cluster_df = df\n",
    "    \n",
    "    # creating column transforming event_date to a unix timestamp for the clustering algorithm to work\n",
    "    cluster_df.event_date_unix = cluster_df['event_date'].apply(lambda x: pd.Timestamp(x).timestamp())\n",
    "\n",
    "    # reshaping to fit clustering algorithm requirements and fitting model\n",
    "    X = np.array(cluster_df.event_date_unix).reshape(-1, 1)\n",
    "    y_km = km.fit_predict(X)\n",
    "\n",
    "    # appending cluster labels back to df\n",
    "    cluster_df['time_period'] = y_km\n",
    "    \n",
    "    # selecting only required columns for returned df\n",
    "    cluster_df = cluster_df[['source_singular', 'time_period']]\n",
    "    \n",
    "    return cluster_df\n",
    "\n",
    "\n",
    "def tag_data(df):\n",
    "    base_df = df[['source_singular']].drop_duplicates()\n",
    "    \n",
    "    for tag_df in [tag_country(df, 10, 1000, 0.75), tag_sub_event_type(df, 10, 1000, 0.85), tag_time_period(df)]:\n",
    "        base_df = sqldf('''\n",
    "            SELECT * FROM base_df a\n",
    "            JOIN tag_df b ON a.source_singular = b.source_singular\n",
    "        ''')\n",
    "\n",
    "    return base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fddaae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/15714/Downloads/EXPANDED_acled_covid19.csv')\n",
    "\n",
    "\n",
    "# getting distinct list of specific event types from the \"sub_event_type\" column\n",
    "typ_df = sqldf('''\n",
    "    SELECT DISTINCT sub_event_type\n",
    "    FROM df\n",
    "''', globals())\n",
    "\n",
    "# generating query to get binary indicators for each sub_event_type\n",
    "query_fmt = ''\n",
    "for i, t in enumerate(typ_df['sub_event_type']):\n",
    "    t_cln = t.replace(\" \", \"_\")\n",
    "    t_cln = t_cln.replace(\"/\", \"_\")\n",
    "    query_fmt += f'sum(CASE WHEN sub_event_type = \"{t}\" THEN 1 ELSE 0 END ) AS \"{t_cln}\"'\n",
    "    if i < len(typ_df['sub_event_type']) - 1:\n",
    "        query_fmt += ',\\n'\n",
    "\n",
    "# applying above query\n",
    "type_cnt_df = sqldf(f'''\n",
    "    SELECT source_singular,\n",
    "    {query_fmt}\n",
    "    FROM df\n",
    "    GROUP BY source_singular\n",
    "''', globals())\n",
    "\n",
    "# getting dataframe of each source and the total of how many times the source was used by ACLED in an event\n",
    "tot_cnt_df = _get_tot_cnt_df(df)\n",
    "\n",
    "# generating query to get percent of sub_event_type reported on by each source for each sub_event_type\n",
    "query_fmt = ''\n",
    "for i, t in enumerate(typ_df['sub_event_type']):\n",
    "    t_cln = t.replace(\" \", \"_\")\n",
    "    t_cln = t_cln.replace(\"/\", \"_\")\n",
    "    t_cln_pct_nm = t_cln + '_pct'\n",
    "    query_fmt += f'cast({t_cln} AS DOUBLE) / cast(total AS DOUBLE) \"{t_cln_pct_nm}\"'\n",
    "    if i < len(typ_df['sub_event_type']) - 1:\n",
    "        query_fmt += ',\\n'\n",
    "\n",
    "# applying above query\n",
    "type_pct_df = sqldf(f'''\n",
    "    SELECT\n",
    "        a.*,\n",
    "        b.total,\n",
    "        {query_fmt}\n",
    "    FROM type_cnt_df a\n",
    "    JOIN tot_cnt_df b\n",
    "        ON a.source_singular = b.source_singular\n",
    "''', globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25f52f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: Peaceful protest\n",
      "mean: 0.7987037190393641 \n",
      "sd: 0.3250837429563895\n",
      "1 sd above mean: 1.1237874619957535\n",
      "\n",
      "\n",
      "Type: Protest with intervention\n",
      "mean: 0.044237577848892866 \n",
      "sd: 0.14085716391020536\n",
      "1 sd above mean: 0.18509474175909824\n",
      "\n",
      "\n",
      "Type: Change to group/activity\n",
      "mean: 0.03217285776679531 \n",
      "sd: 0.1426660169880617\n",
      "1 sd above mean: 0.174838874754857\n",
      "\n",
      "\n",
      "Type: Looting/property destruction\n",
      "mean: 0.004753608956397912 \n",
      "sd: 0.04861290383864563\n",
      "1 sd above mean: 0.05336651279504354\n",
      "\n",
      "\n",
      "Type: Attack\n",
      "mean: 0.020832473741074515 \n",
      "sd: 0.10848405430544657\n",
      "1 sd above mean: 0.12931652804652108\n",
      "\n",
      "\n",
      "Type: Violent demonstration\n",
      "mean: 0.04821643275182222 \n",
      "sd: 0.1493954109656143\n",
      "1 sd above mean: 0.1976118437174365\n",
      "\n",
      "\n",
      "Type: Abduction/forced disappearance\n",
      "mean: 0.0015507361092846669 \n",
      "sd: 0.030467539281174436\n",
      "1 sd above mean: 0.0320182753904591\n",
      "\n",
      "\n",
      "Type: Other\n",
      "mean: 0.012557364258876042 \n",
      "sd: 0.08957009351289237\n",
      "1 sd above mean: 0.10212745777176842\n",
      "\n",
      "\n",
      "Type: Mob violence\n",
      "mean: 0.02225588170728618 \n",
      "sd: 0.10777277328394318\n",
      "1 sd above mean: 0.13002865499122934\n",
      "\n",
      "\n",
      "Type: Arrests\n",
      "mean: 0.0032591085398415856 \n",
      "sd: 0.04306704872426936\n",
      "1 sd above mean: 0.04632615726411095\n",
      "\n",
      "\n",
      "Type: Disrupted weapons use\n",
      "mean: 0.00022887594684686686 \n",
      "sd: 0.007240781113759246\n",
      "1 sd above mean: 0.007469657060606112\n",
      "\n",
      "\n",
      "Type: Excessive force against protesters\n",
      "mean: 0.0019017683236134853 \n",
      "sd: 0.03464273688848619\n",
      "1 sd above mean: 0.036544505212099676\n",
      "\n",
      "\n",
      "Type: Remote explosive/landmine/IED\n",
      "mean: 0.002384808359394105 \n",
      "sd: 0.042767468902827316\n",
      "1 sd above mean: 0.04515227726222142\n",
      "\n",
      "\n",
      "Type: Sexual violence\n",
      "mean: 0.0005570141436134163 \n",
      "sd: 0.01969178370271267\n",
      "1 sd above mean: 0.020248797846326088\n",
      "\n",
      "\n",
      "Type: Armed clash\n",
      "mean: 0.004872014131990907 \n",
      "sd: 0.056349183877178785\n",
      "1 sd above mean: 0.06122119800916969\n",
      "\n",
      "\n",
      "Type: Grenade\n",
      "mean: 6.529288918522145e-05 \n",
      "sd: 0.0026691910140402785\n",
      "1 sd above mean: 0.0027344839032255\n",
      "\n",
      "\n",
      "Type: Agreement\n",
      "mean: 0.0006261503778186995 \n",
      "sd: 0.022275591762999418\n",
      "1 sd above mean: 0.022901742140818117\n",
      "\n",
      "\n",
      "Type: Shelling/artillery/missile attack\n",
      "mean: 0.00080100291096051 \n",
      "sd: 0.0246707835018491\n",
      "1 sd above mean: 0.02547178641280961\n",
      "\n",
      "\n",
      "Type: Air/drone strike\n",
      "mean: 2.3312196941439763e-05 \n",
      "sd: 0.0017070514396701614\n",
      "1 sd above mean: 0.001730363636611601\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evt = df['sub_event_type'].drop_duplicates()\n",
    "\n",
    "import statistics\n",
    "\n",
    "colnms = ['sub_event_type', 'mean', 'sd', 'sd_plus1'] + [f'over_{f}' for f in [0.5001, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]]\n",
    "stdf = pd.DataFrame(columns=colnms )\n",
    "for i in evt:\n",
    "    i_ = i.replace(\" \", \"_\")\n",
    "    i_ = i_.replace(\"/\", \"_\")\n",
    "    m = statistics.mean(type_pct_df[f'{i_}_pct'])\n",
    "    sd = statistics.stdev(type_pct_df[f'{i_}_pct'])\n",
    "    \n",
    "    nr = {'sub_event_type': i, 'mean': m, 'sd': sd, 'sd_plus1': sd + m}\n",
    "    \n",
    "    for f in [0.5001, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]:\n",
    "        c = len(\n",
    "            sqldf(\n",
    "                f'''\n",
    "                    SELECT {i_}_pct\n",
    "                    FROM type_pct_df\n",
    "                    WHERE {i_}_pct >= {f}\n",
    "                ''', globals()))\n",
    "        nr[f'over_{f}'] = c\n",
    "    \n",
    "    stdf = stdf.append(nr, ignore_index = True)\n",
    "    print(f'Type: {i}\\nmean: {m} \\nsd: {sd}\\n1 sd above mean: {sd + m}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef17fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdf.to_csv('tag_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "884baf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_pct_df = sqldf('''\n",
    "    SELECT a.source_singular, a.sub_event_type, total, cast(cnt as double) / cast(b.total as double) `pct` FROM (\n",
    "        SELECT source_singular, sub_event_type, count(*) cnt FROM df\n",
    "        GROUP BY source_singular, sub_event_type ORDER BY source_singular) a\n",
    "    JOIN tot_cnt_df b\n",
    "    ON a.source_singular = b.source_singular\n",
    "''', globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d97ce59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_singular</th>\n",
       "      <th>sub_event_type</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>061.ua</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 News</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Tampa Bay</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/11 Now</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010WINS</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>net.hr</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>news.com.au</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>nncMX</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5696</th>\n",
       "      <td>stiripesurse.ro</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>yam News</td>\n",
       "      <td>Peaceful protest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5698 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_singular    sub_event_type       pct\n",
       "0              061.ua  Peaceful protest  0.800000\n",
       "1              1 News  Peaceful protest  0.800000\n",
       "2        10 Tampa Bay  Peaceful protest  0.857143\n",
       "3           10/11 Now  Peaceful protest  1.000000\n",
       "4            1010WINS  Peaceful protest  0.866667\n",
       "...               ...               ...       ...\n",
       "5693           net.hr  Peaceful protest  1.000000\n",
       "5694      news.com.au  Peaceful protest  1.000000\n",
       "5695            nncMX  Peaceful protest  0.952381\n",
       "5696  stiripesurse.ro  Peaceful protest  1.000000\n",
       "5697         yam News  Peaceful protest  1.000000\n",
       "\n",
       "[5698 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqldf('''\n",
    "    SELECT\n",
    "        a.source_singular,\n",
    "        a.sub_event_type,\n",
    "        a.pct\n",
    "    FROM\n",
    "        tot_pct_df a\n",
    "    JOIN\n",
    "        (SELECT source_singular, max(pct) pctMax FROM tot_pct_df GROUP BY source_singular) b\n",
    "        ON\n",
    "            a.source_singular = b.source_singular\n",
    "            AND a.pct = b.pctMax\n",
    "''', globals())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
